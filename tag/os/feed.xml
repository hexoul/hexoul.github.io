<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="/tag/os/feed.xml" rel="self" type="application/atom+xml" />
  <link href="/" rel="alternate" type="text/html" />
  <updated>2025-06-15T17:18:43+09:00</updated>
  <id>/tag/os/feed.xml</id>

  
  
  

  
    <title type="html">Seunggon Kim | </title>
  

  
    <subtitle>The creative needs diverse points of view and insight.</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">프로세스 동기화의 블로킹 방식</title>
      <link href="/process-sync" rel="alternate" type="text/html" title="프로세스 동기화의 블로킹 방식" />
      <published>2022-05-07T00:00:00+09:00</published>
      <updated>2022-05-07T00:00:00+09:00</updated>
      <id>/process-sync</id>
      <content type="html" xml:base="/process-sync">&lt;p&gt;프로세스 동기화 방식은 임계 구역(critical section)에 진입하기 위해 대기하는 알고리즘(algorithm)에 따라 블로킹(blocking)과 논블로킹(non-blocking)으로 나뉜다.&lt;/p&gt;

&lt;p&gt;구체적으로 진입이 될 때까지 다른 작업을 하지 못하고 무한히 기다릴 가능성이 있다면 블로킹, 그렇지 않고 유한한 시간 또는 단계 내에 진입의 완료가 보장된다면 논블로킹이다. 논블로킹이라 하여 진입 시도 후 임계 구역에 진입할 때까지 대기 시간이 아예 없는 것이 아님을 주의해야 한다.&lt;/p&gt;

&lt;p&gt;논블로킹은 동시 접근이 발생하고 있는 상황에서 어느 정도까지 진행에 지장을 주지 않고 진입을 보장해주느냐에 따라서 단계가 나뉘어 진다. 단계는 wait-free, lock-free 및 obstruction-free가 있다. wait-free에서 obstruction-free로 갈수록 보장이 약해진다.
우선 wait-free의 경우, 시스템 전역적으로 기아(starvation)가 없는 것을 보장해준다. 따라서 접근을 시도했던 모든 프로세스는 유한한 시간 내에 원자성을 지키면서 작업을 완료할 수 있다. 이러한 특성은 실시간성이 보장되어야 하는 실시간 시스템에 적합하다. 하지만 기아를 방지하기 위한 제약이 구현을 복잡하게 만들어 성능은 lock-free 또는 obstruction-free보다 좋지 않을 수도 있다.
lock-free는 기아를 발생시킬 수 있으나, 경쟁이 있더라도 유한한 시간내에 적어도 하나의 프로세스는 성공적으로 작업을 진행할 수 있게 보장해 준다. lock-free의 보장 범위는 wait-free의 부분 집합이므로 모든 wait-free는 lock-free이다.
obstruction-free는 가장 약한 수준의 논블로킹으로, 프로세스가 독립적으로 수행된다면 유한한 시간 내에 작업을 완료할 수 있는 것을 뜻한다. 달리 말해, 독립 수행이 보장되지 못한다면 경쟁을 발생시킬 수 있는 나머지 프로세스를 전부 대기시켜야 유한한 시간 내에 완료할 수 있다는 것을 의미한다. 논블로킹 중에서 제일 제약이 약한만큼, 앞서 모든 wait-free가 lock-free이었던 것처럼 모든 wait-free 또는 모든 lock-free는 obstruction-free도 만족한다고 말할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/기아_상태&quot;&gt;https://ko.wikipedia.org/wiki/기아_상태&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-blocking_algorithm#Wait-freedom&quot;&gt;https://en.wikipedia.org/wiki/Non-blocking_algorithm#Wait-freedom&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-blocking_algorithm#Lock-freedom&quot;&gt;https://en.wikipedia.org/wiki/Non-blocking_algorithm#Lock-freedom&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-blocking_algorithm#Obstruction-freedom&quot;&gt;https://en.wikipedia.org/wiki/Non-blocking_algorithm#Obstruction-freedom&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Starvation_(computer_science)&quot;&gt;https://en.wikipedia.org/wiki/Starvation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Seunggon Kim</name>
        
        
      </author>

      

      
        <category term="os" />
      

      
        <summary type="html">프로세스 동기화 방식은 임계 구역(critical section)에 진입하기 위해 대기하는 알고리즘(algorithm)에 따라 블로킹(blocking)과 논블로킹(non-blocking)으로 나뉜다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">스핀락, 세마포어 그리고 뮤텍스</title>
      <link href="/mutex" rel="alternate" type="text/html" title="스핀락, 세마포어 그리고 뮤텍스" />
      <published>2022-05-06T00:00:00+09:00</published>
      <updated>2022-05-06T00:00:00+09:00</updated>
      <id>/mutex</id>
      <content type="html" xml:base="/mutex">&lt;p&gt;스핀락(spinlock)과 세마포어(semaphore) 그리고 뮤텍스(mutex)는 모두 공유 자원에 대한 동시 접근을 제어하기 위해 쓰이는 락(lock)이다.&lt;/p&gt;

&lt;p&gt;공유가 불가능한 자원에 동시 접근을 허용한다면, 동시성이 제어되지 않아 의도치않게 값이 덮어써지는 등 데이터가 일관성을 잃게 될 가능성이 생기기 때문이다. 이에 따라 락을 통해 공유 자원에 접근하는 부분, 즉 동시에 접근되면 안되는 구역인 임계 구역(critical section)의 진입을 통제함으로써 일관성을 보장한다.&lt;/p&gt;

&lt;p&gt;스핀락, 세마포어 및 뮤텍스는 임계 구역에 진입하고 나갈 때 락과 언락(unlock)을 하는 방법이 서로 다르게 구현된다. 우선 스핀락은 임계 구역에 진입할 때까지 CPU를 놓지 않고 계속하여 락의 취득을 시도하는 busy waiting으로 구현된다. 세마포어와 뮤텍스도 busy waiting으로 구현될 수 있는데, 이 경우 락을 취득하는 방식에는 차이가 없다. 하지만 락을 요청한 후 취득할 때까지 CPU를 소모하지 않고 잠들어 있도록 대기 큐(wait queue)를 사용하도록 구현될 경우 차이가 생긴다. 금방 임계 구역에 진입이 불가능한 경우, 수행 가능한 다른 프로세스가 수행되고 있을 수 있도록 CPU를 낭비하지 않는 세마포어나 뮤텍스가 효율적이다. 하지만 금방 진입이 가능한 경우 프로세스가 잠들었다가 깨어나는 문맥 교환(context switch)이 필요없는 스핀락이 더 효율적이다.&lt;/p&gt;

&lt;p&gt;세마포어는 임계 구역에 동시 진입을 허용할 프로세스의 수에 따라 1개만 허용하면 이진 세마포어(binary semaphore) 그 외에는 계수 세마포어(counting semaphore)라 한다. 뮤텍스도 임계 구역에 동시 진입을 허용할 프로세스가 1개이기 때문에 이진 세마포어와 동일하다 생각할 수 있지만 그렇지 않다. 뮤텍스의 경우, 락을 취득한 프로세스만이 언락을 할 수 있다는 점이 다르다. 따라서 뮤텍스를 통해 임계 구역에 진입한 프로세스가 비정상적으로 종료되거나 무한 루프에 빠진다면 같은 락을 바라보고 임계 구역에 진입하려고 시도하고 있던 프로세스는 영원히 진입할 수 없게 된다.
반면, 세마포어는 락의 동시 접근만을 제어할 뿐 언락을 시도하는 프로세스가 락을 취득했던 프로세스인지는 확인하지는 않는다. 이에 따라, 위와 같이 락을 취득했던 프로세스가 락을 해제하지 않은 채 비정상 종료가 되었다고 하더라도, 세마포어에서는 다른 프로세스가 대신 언락을 하여 무한히 대기하는 상황을 회피할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/스핀락&quot;&gt;https://ko.wikipedia.org/wiki/스핀락&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/세마포어&quot;&gt;https://ko.wikipedia.org/wiki/세마포어&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/락_(컴퓨터_과학)&quot;&gt;https://ko.wikipedia.org/wiki/뮤텍스&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spinlock&quot;&gt;https://en.wikipedia.org/wiki/Spinlock&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Semaphore_(programming)&quot;&gt;https://en.wikipedia.org/wiki/Semaphore&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Lock_(computer_science)&quot;&gt;https://en.wikipedia.org/wiki/Mutex&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Seunggon Kim</name>
        
        
      </author>

      

      
        <category term="os" />
      

      
        <summary type="html">스핀락(spinlock)과 세마포어(semaphore) 그리고 뮤텍스(mutex)는 모두 공유 자원에 대한 동시 접근을 제어하기 위해 쓰이는 락(lock)이다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">프로세서와 프로세스</title>
      <link href="/processor" rel="alternate" type="text/html" title="프로세서와 프로세스" />
      <published>2022-04-13T00:00:00+09:00</published>
      <updated>2022-04-13T00:00:00+09:00</updated>
      <id>/processor</id>
      <content type="html" xml:base="/processor">&lt;p&gt;간단하게 말하면 프로세스(process)는 실행해야 하는 일련의 작업이고, 프로세서(processor)는 프로세스를 실행하는 주체이다. 나아가 어떤 프로세서가 어떤 프로세스를 얼마나 실행시킬지에 대한 실행을 계획하는 것을 스케줄링이라 한다.&lt;/p&gt;

&lt;p&gt;만약 프로세서와 프로세스가 하나씩만 있다면 항상 같은 프로세서가 같은 프로세스를 실행할 것이므로 스케줄은 항상 같아 스케줄링이 필요없다. 하지만 프로세스의 수가 많다면 어떤 프로세스를 언제 실행할 것인지 스케줄링을 할 필요가 생긴다. 만약 스케줄링을 하지 않고 시작한 프로세스를 다 끝내고 나서야 다음 프로세스를 실행시킨다면 실행 중인 프로세스를 제외한 나머지 프로세스들은 기약없이 기다리게 될 수도 있다. 왜냐하면 프로그램의 구현이나 예외 등에 따라 프로세스 수행 중 대기시간이 무한대가 될 수 있기때문에 종료시간이 보장되지 않기 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;멀티-프로세서와-멀티-코어&quot;&gt;멀티 프로세서와 멀티 코어&lt;/h3&gt;

&lt;p&gt;멀티 프로세서(multiprocessor)는 “멀티(multi-)”라는 뜻대로 복수의 프로세서를 가지는 것을 의미한다. 각 프로세서는 단일 직접 회로, 즉 하나의 칩이라는 것 까지만 정의되고 어떻게 구성되는 지는 알 수 없다. 하지만 한 프로세서가 적어도 하나의 CPU는 가지고 있을 것이므로 병렬 처리가 가능한 시스템이라는 사실은 알 수 있다. 주기억장치는 공유되지만 각 프로세서는 자신의 캐시와 CPU를 가지고 서로 다른 프로세스의 서로 다른 명령어를 동시에 실행시킬 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;500&quot; src=&quot;assets/images/processor-fig1.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;반면 멀티 코어는 멀티 코어 프로세서(multi-core processor)의 줄임말로 하나의 프로세서 내에 두 개 이상의 코어가 있는 것을 말한다. 코어 수에 따라 구체적인 명칭을 사용하기도 한다. 예를 들어, 코어가 두 개일 경우 듀얼 코어(dual-core), 네 개일 경우 쿼드 코어(quad-core)라고 부른다. 복수의 프로세스를 동시에 실행시킬 수 있다는 점은 멀티 프로세서와 같지만 복수의 코어가 같은 칩 안에 있다는 점이 다르다. 따라서 코어 간 거리가 물리적으로 가깝기 때문에 코어 간 정보 전달이나 프로세스를 한 프로세서에서 다른 프로세서로 옮기는 프로세스 이주(process migration) 시에 멀티 프로세서보다 오버헤드(overhead)가 적은 등 여러 이점이 있다.&lt;/p&gt;

&lt;p&gt;그렇다면 싱글 코어 프로세서가 두 개인 시스템과 듀얼 코어를 비교한다면 어떤 것이 빠를까? 항상 우세인 것은 없고 상황에 따라 달라진다. 코어 간의 상호 작용이 없다면 클럭 속도(clock rate)에 의해 좌우될 수 있다. 클럭 속도가 높을 수록 같은 시간에 처리할 수 있는 명령어의 수가 많으므로, 전체 코어의 수가 같더라도 클럭 속도가 높은 쪽이 처리량이 높을 확률이 크다. 클럭 속도가 같다면 다음으로 캐시(cache)의 영향을 생각해 볼 수 있다. 프로세서마다 별도로 캐시를 가지기에 듀얼 코어는 동시에 두 코어가 같은 캐시에 접근한다. 자원을 공유할 일이 없는 서로 다른 프로세스를 실행시킨다면 경쟁적으로 캐시를 사용하여 싱글 코어에 비하여 캐시 실패(cache miss)를 더 많이 유발시킬 수도 있다. 이 경우 싱글 코어가 더 유리한 환경이 된다. 만약 반대로 동일한 프로그램을 다중으로 실행하는 등 동일한 메모리에 접근을 많이 하는 상황이 된다면 캐시 적중(cache hit)이 많아져 멀티 코어가 더 유리해질 것이다. 이렇듯 설계와 실제 실행 환경에 따라 드러나는 장단점을 인지해두는 것이 중요하다.&lt;/p&gt;

&lt;p&gt;추가적으로 UMA(Uniform Memory Access)와 NUMA(Non-uniform Memory Access)도 알아두면 좋다. UMA와 NUMA는 프로세서가 많아지는 병렬 컴퓨팅(parallel computing) 환경 하에서 메모리를 효율적으로 사용하기 위해 고안된 설계들이다. UMA는 각 코어에서 메모리에 접근하는 속도가 균등하도록 설계된 것으로, 접근 시간이 결정적이지만 동시에 여러 프로세서가 한 번에 메모리에 접근할 수 없어 시분할에 적합하다. NUMA는 UMA와 대조되는 개념으로 각 프로세서가 별도의 메모리 컨트롤러를 가지고 계층 구조로 연결되어 있어 요청한 메모리의 물리적 위치에 따라 접근 속도가 매번 달라질 수 있다. 대신 동시에 접근할 수 있어 일반적으로 UMA보다 빠르고 실시간성이 요구되는 시스템에 적합하다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/프로세스&quot;&gt;https://ko.wikipedia.org/wiki/프로세스&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/다중_처리&quot;&gt;https://ko.wikipedia.org/wiki/다중_처리&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/불균열_기억_장치_접근&quot;&gt;https://ko.wikipedia.org/wiki/불균열_기억_장치_접근&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Process_(computing)&quot;&gt;https://en.wikipedia.org/wiki/Process&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Uniprocessor_system&quot;&gt;https://en.wikipedia.org/wiki/Uniprocessor_system&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Uniform_memory_access&quot;&gt;https://en.wikipedia.org/wiki/Uniform_memory_access&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Non-uniform_memory_access&quot;&gt;https://en.wikipedia.org/wiki/Non-uniform_memory_access&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Seunggon Kim</name>
        
        
      </author>

      

      
        <category term="os" />
      

      
        <summary type="html">간단하게 말하면 프로세스(process)는 실행해야 하는 일련의 작업이고, 프로세서(processor)는 프로세스를 실행하는 주체이다. 나아가 어떤 프로세서가 어떤 프로세스를 얼마나 실행시킬지에 대한 실행을 계획하는 것을 스케줄링이라 한다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">인터럽트 벡터 테이블과 ISR</title>
      <link href="/isr" rel="alternate" type="text/html" title="인터럽트 벡터 테이블과 ISR" />
      <published>2022-03-20T00:00:00+09:00</published>
      <updated>2022-03-20T00:00:00+09:00</updated>
      <id>/isr</id>
      <content type="html" xml:base="/isr">&lt;p&gt;인터럽트는 IRQ(Interrupt ReQuest)라고 하는 하드웨어 전기신호로 회로의 버스(bus)를 통해 CPU에 전달된다.&lt;/p&gt;

&lt;p&gt;이 때 사전에 작성된 인터럽트 벡터 테이블(interrupt vector table)을 참조하여 발생된 인터럽트에 해당하는 핸들러를 호출하게 된다. 호출되는 함수는 ISR(Interrupt Service Routine) 또는 인터럽트 핸들러(interrupt handler)라고 불린다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;500&quot; src=&quot;assets/images/isr-fig1.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ISR은 지터(jitter)로 인한 동시성(concurrency) 저해 또는 문맥 교환 오버헤드(context switch overhead) 등 많은 이슈가 있어 실행시간이 최소화 되도록 작성하라고 권장된다. 그럼에도 불구하고 처리 시간이 길어지거나 인터럽트가 많이 발생하는 상황이 있을 수 있기 때문에, 현대의 운영체제에서는 인터럽트를 두 단계로 나누어 처리하기도 한다.&lt;/p&gt;

&lt;p&gt;두 단계는 각각 FLIH(First-Level Interrupt Handler)와 SLIH(Second-Level Interrupt Handler)로 불린다. FLIH에서 필수적인 작업만 최소한으로 처리한 뒤 SLIH로 넘겨 나머지를 처리한다. SLIH는 커널 스레드(thread)가 실행시키는데, 사용자 프로세스처럼 스케줄러(scheduler)가 CPU를 할당할 때까지 대기해야 한다. 따라서 실행 시작 시간과 완료 시간의 보장이 안된다는 것을 유념해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/인터럽트&quot;&gt;https://ko.wikipedia.org/wiki/인터럽트&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/인터럽트_벡터_테이블&quot;&gt;https://ko.wikipedia.org/wiki/인터럽트_벡터_테이블&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/인터럽트_핸들러&quot;&gt;https://ko.wikipedia.org/wiki/인터럽트_핸들러&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interrupt&quot;&gt;https://en.wikipedia.org/wiki/Interrupt&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interrupt_vector_table&quot;&gt;https://en.wikipedia.org/wiki/Interrupt_vector_table&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interrupt_handler&quot;&gt;https://en.wikipedia.org/wiki/Interrupt_handler&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Jitter&quot;&gt;https://en.wikipedia.org/wiki/Jitter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Seunggon Kim</name>
        
        
      </author>

      

      
        <category term="os" />
      

      
        <summary type="html">인터럽트는 IRQ(Interrupt ReQuest)라고 하는 하드웨어 전기신호로 회로의 버스(bus)를 통해 CPU에 전달된다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">하드웨어 인터럽트와 소프트웨어 인터럽트</title>
      <link href="/interrupt" rel="alternate" type="text/html" title="하드웨어 인터럽트와 소프트웨어 인터럽트" />
      <published>2022-03-17T00:00:00+09:00</published>
      <updated>2022-03-17T00:00:00+09:00</updated>
      <id>/interrupt</id>
      <content type="html" xml:base="/interrupt">&lt;p&gt;인터럽트(interrupt)는 프로세서에 이벤트를 알려 현재 프로세서가 실행 중인 컨텍스트에서 벗어나 별도의 컨텍스트를 실행하는 것을 가능하게 한다.&lt;/p&gt;

&lt;p&gt;이 때 이벤트가 어디에서 발생했는지에 따라 하드웨어 인터럽트 또는 소프트웨어 인터럽트로 분류된다.&lt;/p&gt;

&lt;p&gt;하드웨어 인터럽트는 키보드, 마우스 또는 프린터와 같은 외부 하드웨어 장치로부터도 발생할 수 있지만 내부에도 존재한다. 대표적으로 하드웨어 타이머의 경우, CPU 내부에서 클락(clock)을 일정한 주기를 가지고 인터럽트로 발생시켜 동기화를 가능케 한다.&lt;/p&gt;

&lt;p&gt;소프트웨어 인터럽트는 시스템 콜을 통해서 의도적으로 발생시킬 수도 있지만, 의도하지 않았는데도 프로그램 실행 중에 발생할 수 있다. 예기치 않게 발생한 인터럽트는 트랩(trap) 또는 예외(exception)라 불린다. 한가지 예로 어떤 수를 0으로 나눌 때 발생하는 divide-by-zero가 있다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/인터럽트&quot;&gt;https://ko.wikipedia.org/wiki/인터럽트&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interrupt#Hardware_interrupts&quot;&gt;https://en.wikipedia.org/wiki/Interrupt#Hardware_interrupts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interrupt#Software_interrupts&quot;&gt;https://en.wikipedia.org/wiki/Interrupt#Software_interrupts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Seunggon Kim</name>
        
        
      </author>

      

      
        <category term="os" />
      

      
        <summary type="html">인터럽트(interrupt)는 프로세서에 이벤트를 알려 현재 프로세서가 실행 중인 컨텍스트에서 벗어나 별도의 컨텍스트를 실행하는 것을 가능하게 한다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">운영체제와 커널</title>
      <link href="/os-n-kernel" rel="alternate" type="text/html" title="운영체제와 커널" />
      <published>2022-03-03T00:00:00+09:00</published>
      <updated>2022-03-03T00:00:00+09:00</updated>
      <id>/os-n-kernel</id>
      <content type="html" xml:base="/os-n-kernel">&lt;p&gt;일반적으로 커널은 운영체제에서 핵심이 되는 부분이라고 정의된다. 핵심이란 무엇일까?&lt;/p&gt;

&lt;p&gt;핵심이라 분류하여 나누는 기준은 시스템 자체에 영향을 줄 수 있는 코드의 실행 여부이다. 즉, 보안 취약점이 될 가능성을 가진 코드로 해석할 수도 있다. 구체적으로 메모리와 하드웨어의 보호를 위한 실행 영역의 분리가 커널의 목적 중 하나이다.&lt;/p&gt;

&lt;p&gt;메모리 보호가 되지않을 경우 세그멘테이션 오류(segmentation fault), 메모리 침범 등 다양한 문제가 발생할 수 있다. 읽기 전용 메모리 영역에 쓰기를 시도한 경우, 하드웨어에 의해 인지되면 세그멘테이션 오류가 발생하지만 인지가 안됐을 때는 오염이 발생된 채로 프로그램이 계속 수행되어 더욱 심한 부작용을 야기할 수 있다. 가상 주소(virtual address) 를 채용한 운영체제에서는 프로세스 별로 페이지 테이블을 관리하여 원칙적으로는 다른 프로세스의 메모리 영역에 접근할 수 없으나, 취약점이 노출된 경우 임의로 메모리를 갈취하거나 수정할 수도 있게 된다. 따라서 보안을 위해 시스템 자체에 영향을 줄 수 있는 작업들은 커널이라는 분리된 공간에서 특별한 권한을 가지고 실행하도록 설계된다.&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;500&quot; src=&quot;assets/images/os-n-kernel-fig1.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;메모리 보호를 위해 실제 실행 환경은 사용자 모드와 커널 모드로 구분된다. 커널 모드는 특권 모드(privileged mode) 라고도 한다. 사용자 애플리케이션이 기본적으로 사용자 모드로 실행되고, 애플리케이션에서 권한이 요구되는 커널의 기능이 필요할 때는 시스템 콜 인터페이스를 통해 실행을 요청함으로써 시스템 서비스를 받을 수 있다. 커널 영역은 격리되어 보호받기에 직접 실행할 수 없기 때문이다.
모드의 이름 때문에 커널은 커널 모드에서만 실행된다고 생각될 수 있지만 반드시 그렇지는 않다. 커널은 커널 모드로만 실행되는 것이 아니고, 사용자 모드도 사용자 애플리케이션만 실행하는 모드가 아니다. 커널 설계에 따라 달라진다는 것이 정확한 표현이다. 커널 코드를 커널 모드에서만 실행하는 운영체제도 있고, 커널 코드 중 일부를 사용자 모드로 실행하는 운영체제도 있다. 예를 들어 특정 커널에서 일부 디바이스 드라이버는 사용자 모드에서 실행된다.&lt;/p&gt;

&lt;p&gt;커널 설계는 운영체제의 수 만큼 다양하지만 운영체제에서 차지하는 커널의 비중이나 추상화 방법에 따라 분류하여 단일형 커널(monolithic kernel), 마이크로커널(microkernel), 하이브리드 커널(hybrid kernel), 엑소 커널(exokernel) 등으로 부른다. 단일형 커널의 경우 이름 그대로 운영체제의 모든 기능을 단일 메모리 공간 내에서 실행하는 구조로 커널이 운영체제의 100%를 차지한다. 반면 마이크로커널은 커널의 크기를 최소화한 커널이다. 하이브리드 커널은 단일형 커널과 마이크로커널의 장점을 합치려고 시도한 커널이다.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/운영_체제&quot;&gt;https://ko.wikipedia.org/wiki/운영_체제&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Operating_system&quot;&gt;https://en.wikipedia.org/wiki/Operating_system&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_(operating_system)&quot;&gt;https://en.wikipedia.org/wiki/Kernel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>Seunggon Kim</name>
        
        
      </author>

      

      
        <category term="os" />
      

      
        <summary type="html">일반적으로 커널은 운영체제에서 핵심이 되는 부분이라고 정의된다. 핵심이란 무엇일까?</summary>
      

      
      
    </entry>
  
</feed>
